{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef939b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import to_categorical\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce24d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4799994\n",
      "4800000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(os.getcwd(),\"data/train.csv\"),encoding='latin-1')\n",
    "data.columns = [\"polarity\",\"id\",\"date\",\"query\",\"user\",\"text\"]\n",
    "\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
    "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
    "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
    "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
    "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
    "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
    "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
    "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "# def cleanupat(string):\n",
    "#     newstring = [word for word in string.split() if word[0]!='@']\n",
    "#     return \" \".join(newstring)\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join([word for word in x.split() if word[0]!='@']))\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join([word for word in x.split() if word not in (stopwords)]))\n",
    "print(data[data['polarity']==0].size)\n",
    "# print(data[data['polarity']==1].size)\n",
    "# print(data[data['polarity']==2].size)\n",
    "# print(data[data['polarity']==3].size)\n",
    "print(data[data['polarity']==4].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703870f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 3000\n",
    "max_len = 50\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X, maxlen = max_len)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4afe9f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 128)           384000    \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 50, 128)           0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433538 (1.65 MB)\n",
      "Trainable params: 433538 (1.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "# model.add(SpatialDropout1D(0.4))\n",
    "# model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(2,activation='softmax'))\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.7))\n",
    "model.add(LSTM(64, dropout=0.4, recurrent_dropout=0.4))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab7ee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6700, 50) (6700, 2)\n",
      "(3300, 50) (3300, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['polarity']).values\n",
    "smallsize = 10000\n",
    "X_small = X[np.random.choice(X.shape[0], smallsize, replace=False)]\n",
    "Y_small = Y[np.random.choice(Y.shape[0], smallsize, replace=False)]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_small,Y_small, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd0e976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "210/210 - 10s - loss: 0.6937 - accuracy: 0.5033 - 10s/epoch - 46ms/step\n",
      "Epoch 2/12\n",
      "210/210 - 9s - loss: 0.6879 - accuracy: 0.5570 - 9s/epoch - 42ms/step\n",
      "Epoch 3/12\n",
      "210/210 - 9s - loss: 0.6676 - accuracy: 0.5951 - 9s/epoch - 42ms/step\n",
      "Epoch 4/12\n",
      "210/210 - 9s - loss: 0.6398 - accuracy: 0.6328 - 9s/epoch - 42ms/step\n",
      "Epoch 5/12\n",
      "210/210 - 9s - loss: 0.6096 - accuracy: 0.6693 - 9s/epoch - 42ms/step\n",
      "Epoch 6/12\n",
      "210/210 - 9s - loss: 0.5837 - accuracy: 0.6831 - 9s/epoch - 43ms/step\n",
      "Epoch 7/12\n",
      "210/210 - 9s - loss: 0.5647 - accuracy: 0.7006 - 9s/epoch - 43ms/step\n",
      "Epoch 8/12\n",
      "210/210 - 9s - loss: 0.5447 - accuracy: 0.7142 - 9s/epoch - 42ms/step\n",
      "Epoch 9/12\n",
      "210/210 - 9s - loss: 0.5142 - accuracy: 0.7367 - 9s/epoch - 42ms/step\n",
      "Epoch 10/12\n",
      "210/210 - 9s - loss: 0.5019 - accuracy: 0.7454 - 9s/epoch - 42ms/step\n",
      "Epoch 11/12\n",
      "210/210 - 9s - loss: 0.4887 - accuracy: 0.7584 - 9s/epoch - 42ms/step\n",
      "Epoch 12/12\n",
      "210/210 - 9s - loss: 0.4574 - accuracy: 0.7724 - 9s/epoch - 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x299f49b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs = 12, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fcd516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.9672 - accuracy: 0.4920 - 310ms/epoch - 10ms/step\n",
      "score: 0.97\n",
      "acc: 0.49\n"
     ]
    }
   ],
   "source": [
    "validation_size = 100\n",
    "def chooserandom(matrix, n):\n",
    "    return matrix[np.random.choice(matrix.shape[0],n,replace=False)]\n",
    "# X_validate = chooserandom(X_test,validation_size)\n",
    "# Y_validate = chooserandom(X_test,validation_size)\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "\n",
    "score,acc = model.evaluate(X_validate, Y_validate, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e6c7219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_acc 46.07843137254902 %\n",
      "neg_acc 52.44897959183673 %\n"
     ]
    }
   ],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(X_validate)):\n",
    "    \n",
    "    result = model.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 0)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "       \n",
    "    if np.argmax(Y_validate[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "sometestthing = tokenizer.texts_to_sequences([\"Looks like you're having a good day\"])\n",
    "sometestthing = pad_sequences(sometestthing, maxlen=max_len, dtype='int32', value=0)\n",
    "sometestthing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26c338da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am so proud of you <3\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "testvalue = input()\n",
    "sometestthing = tokenizer.texts_to_sequences([testvalue])\n",
    "sometestthing = pad_sequences(sometestthing, maxlen=max_len, dtype='int32', value=0)\n",
    "sometestthing.shape\n",
    "sentiment = model.predict(sometestthing, batch_size=1,verbose = 0)\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maketest():\n",
    "    testvalue = input(\"Input your prompt:\").lower()\n",
    "    sometestthing = tokenizer.texts_to_sequences([testvalue])\n",
    "    sometestthing = pad_sequences(sometestthing, maxlen=max_len, dtype='int32', value=0)\n",
    "    sometestthing.shape\n",
    "    sentiment = model.predict(sometestthing, batch_size=1,verbose = 0)\n",
    "    if(np.argmax(sentiment) == 0):\n",
    "        print(\"negative\")\n",
    "    elif (np.argmax(sentiment) == 1):\n",
    "        print(\"positive\")\n",
    "maketest()\n",
    "maketest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a89cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import profanity_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305f73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
